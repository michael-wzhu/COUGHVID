{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/parulnith/7f8c174e6ac099e86f0495d3d9a4c01e/untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNnM2w-HCeb1"
   },
   "source": [
    "# Cough classification notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装 ffmpeg\n",
    "\n",
    "# apt update\n",
    "# apt install ffmpeg\n",
    "# ffmpeg -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2l3sppZMCydR"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gt3fyg6dCNvX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-nas/cough_videos\n"
     ]
    }
   ],
   "source": [
    "# feature extractoring and preprocessing data\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# #Keras\n",
    "# import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%cd ../../\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPe_ebYuDqr5"
   },
   "source": [
    "## Extracting cough audios and features\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We use [COUGHVID](https://zenodo.org/record/7024894#.YysPHHZBybg) dataset for classification. \n",
    "<br>\n",
    "<br>\n",
    "数据原本将每段咳嗽音区分为 i.e\n",
    " * COVID-19\n",
    " * healthy\n",
    " * symptomatic\n",
    " \n",
    "Total dataset: xxx samples\n",
    "\n",
    "\n",
    "我们现在将任务改为二分类：healthy (label 0) vs unhealthy (label 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "neqMS0VoDpN5"
   },
   "source": [
    "## Meta data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3258/40145 [00:01<00:13, 2800.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('COVID-19', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 3854/40145 [00:01<00:18, 1981.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('lower_infection', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 5437/40145 [00:02<00:10, 3384.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'upper_infection', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 10502/40145 [00:05<00:22, 1306.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 10955/40145 [00:05<00:20, 1413.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'upper_infection', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 16618/40145 [00:09<00:16, 1416.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 21557/40145 [00:13<00:12, 1430.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('lower_infection', 'obstructive_disease', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24179/40145 [00:15<00:10, 1528.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('lower_infection', 'upper_infection', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26104/40145 [00:16<00:09, 1421.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'healthy_cough', 'upper_infection')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 27794/40145 [00:17<00:09, 1307.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28201/40145 [00:18<00:08, 1343.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('healthy_cough', 'upper_infection', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 37474/40145 [00:24<00:01, 1340.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None ('lower_infection', 'COVID-19', 'healthy_cough')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40145/40145 [00:26<00:00, 1508.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效样本：  11630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看每个json文件，选取标注\n",
    "\n",
    "import json\n",
    "\n",
    "dict_id2label = {}\n",
    "\n",
    "folder = './datasets/coughvid_v1/public_dataset'\n",
    "count = 0\n",
    "for filename in tqdm(os.listdir(folder)):\n",
    "#     print(filename)\n",
    "    if not filename.endswith(\"json\"):\n",
    "        continue\n",
    "    \n",
    "    annotation_info = json.load(\n",
    "        open(os.path.join(folder, filename), \"r\", encoding=\"utf-8\")\n",
    "    )\n",
    "#     print(annotation_info)\n",
    "    \n",
    "    expert_anno_1 = annotation_info.get(\"expert_labels_1\")\n",
    "    diagnosis_1 = None\n",
    "    if expert_anno_1:\n",
    "        diagnosis_1 = expert_anno_1[\"diagnosis\"]\n",
    "        if expert_anno_1[\"quality\"] == \"no_cough\":\n",
    "            diagnosis_1 = None\n",
    "    \n",
    "    expert_anno_2 = annotation_info.get(\"expert_labels_2\")\n",
    "    diagnosis_2 = None\n",
    "    if expert_anno_2:\n",
    "        diagnosis_2 = expert_anno_2[\"diagnosis\"]\n",
    "        if expert_anno_2[\"quality\"] == \"no_cough\":\n",
    "            diagnosis_2 = None\n",
    "    \n",
    "    expert_anno_3 = annotation_info.get(\"expert_labels_3\")\n",
    "    diagnosis_3 = None\n",
    "    if expert_anno_3:\n",
    "        diagnosis_3 = expert_anno_3.get(\"diagnosis\")\n",
    "#         diagnosis_3 = expert_anno_3[\"diagnosis\"]\n",
    "        if expert_anno_3[\"quality\"] == \"no_cough\":\n",
    "            diagnosis_3 = None\n",
    "    \n",
    "    status = annotation_info.get(\"status\")\n",
    "    if diagnosis_1 is None and diagnosis_2 is None and diagnosis_3 is None and status is None:\n",
    "        continue\n",
    "    \n",
    "    diagnose_label = None\n",
    "    \n",
    "    if status:\n",
    "        if status == \"healthy\":\n",
    "            diagnose_label = \"healthy\"\n",
    "        else:\n",
    "            diagnose_label = \"unhealthy\"\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        if set([diagnosis_1, diagnosis_2, diagnosis_3]) == set([\"healthy_cough\", None]):\n",
    "            diagnose_label = \"healthy\"\n",
    "        elif set([diagnosis_1, diagnosis_2, diagnosis_3]) == set([\"healthy_cough\"]):\n",
    "            diagnose_label = \"healthy\"\n",
    "        elif \"healthy\" not in json.dumps([diagnosis_1, diagnosis_2, diagnosis_3]):\n",
    "            diagnose_label = \"unhealthy\"\n",
    "        else:   \n",
    "            print(status, (diagnosis_1, diagnosis_2, diagnosis_3))\n",
    "            if \"\\\"healthy_cough\\\", \\\"healthy_cough\\\"\" not in json.dumps(sorted([diagnosis_1, diagnosis_2, diagnosis_3])):\n",
    "                diagnose_label = \"unhealthy\"\n",
    "            else:\n",
    "                diagnose_label = \"healthy\"\n",
    "    \n",
    "    count += 1\n",
    "    dict_id2label[filename.replace(\".json\", \"\")] = 1 if diagnose_label == \"unhealthy\" else 0\n",
    "\n",
    "print(\"有效样本： \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "负样本率：  0.7428202923473775\n"
     ]
    }
   ],
   "source": [
    "# 正负样本数量：\n",
    "neg_sample = 0   # healthy coughs\n",
    "for k, v in dict_id2label.items():\n",
    "    if v == 0:\n",
    "        neg_sample += 1\n",
    "\n",
    "print(\"负样本率： \", neg_sample / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piwUwgP5Eef9"
   },
   "source": [
    "## Extracting features from Spectrogram\n",
    "\n",
    "\n",
    "We will extract\n",
    "\n",
    "* Mel-frequency cepstral coefficients (MFCC)(20 in number)\n",
    "* Spectral Centroid,\n",
    "* Zero Crossing Rate\n",
    "* Chroma Frequencies\n",
    "* Spectral Roll-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__g8tX8pDeIL"
   },
   "outputs": [],
   "source": [
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}_mean'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}_std'\n",
    "header += ' label'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBlT448pEqR9"
   },
   "source": [
    "## Extracting the Spectrogram and features for every Audio\n",
    "\n",
    "We write the data to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsSQmB0PE3Iu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 4552/40145 [25:33<2:42:19,  3.65it/s]"
     ]
    }
   ],
   "source": [
    "f = open('./datasets/coughvid_v1/features/data.csv', 'w', encoding=\"utf-8\")\n",
    "f.write(header + \"\\n\")\n",
    "\n",
    "cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "list_durations = []\n",
    "list_files = os.listdir(folder)\n",
    "import random\n",
    "random.shuffle(list_files)\n",
    "for filename in tqdm(list_files):\n",
    "    \n",
    "    if filename.endswith(\"json\"):\n",
    "        continue\n",
    "    if filename.endswith(\"csv\"):\n",
    "        continue\n",
    "    \n",
    "    idx = filename.split(\".\")[0]\n",
    "    if idx not in dict_id2label:\n",
    "        continue\n",
    "    \n",
    "    label = dict_id2label[idx]\n",
    "    \n",
    "    # print(label, idx)\n",
    "    \n",
    "    # load file\n",
    "    y, sr = librosa.load(os.path.join(folder, filename), mono=True, duration=30)\n",
    "    # print(y.shape)\n",
    "    # print(sr)\n",
    "    dur = librosa.get_duration(y=y, sr=sr)\n",
    "    list_durations.append(dur)\n",
    "    # print(\"持续时间: \", dur)\n",
    "    \n",
    "    plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "    plt.axis('off');\n",
    "    plt.savefig(f\"./datasets/coughvid_v1/spectrograms/{idx}-label_{label}.png\", dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y, )\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "\n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.std(e)}'\n",
    "            \n",
    "    to_append += f' {label}'\n",
    "    # print(to_append)\n",
    "    f.write(to_append + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 录音时长分布\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.hist(list_durations, bins=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yfdo1cj6V7d"
   },
   "source": [
    "The data has been extracted into a [data.csv](https://github.com/parulnith/Music-Genre-Classification-with-Python/blob/master/data.csv) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgeCZSKQEp1A"
   },
   "source": [
    "# Analysing the Data in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "Kr5_EdpD9dyh",
    "outputId": "81fd4a29-93fa-44f8-bf90-2f99981f761a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/coughvid_v1/features/data.csv', sep=\" \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iHrDHCaR9gKR",
    "outputId": "7d32943a-1ad5-4a59-c13a-beebeb36e4c2"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veD5BgX49hZa"
   },
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.baseline1_feature_extraction.tree_training_utils import train_cv_with_thres, threshold_prob, threshold_prob_via_jordan\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "random_state = 100\n",
    "cbt = CatBoostClassifier(verbose=0, allow_writing_files=False, random_state=random_state)\n",
    "lgb = LGBMClassifier(is_unbalance=True, random_state=random_state)\n",
    "xgb = XGBClassifier(verbose=0, scale_pos_weight=3, enable_categorical=True, random_state=random_state)\n",
    "logistic = LogisticRegression(verbose=0, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models \n",
    "list_model_names = [\n",
    "    \"cbt\",\n",
    "    \"lgb\",\n",
    "    \"xgb\",\n",
    "    \"logistic\",\n",
    "#     \"stack\"\n",
    "]\n",
    "list_model_clfs = [\n",
    "    cbt, \n",
    "    lgb, \n",
    "    xgb, \n",
    "    logistic, \n",
    "#     stack\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "features = [w for w in data.columns if w not in [\"label\"]]\n",
    "print(features)\n",
    "\n",
    "for clf_name, clf in zip(list_model_names, list_model_clfs):\n",
    "    \n",
    "    res = train_cv_with_thres(data,\n",
    "                        clf,\n",
    "                        features,\n",
    "                        num_folds=5,\n",
    "                        random_state=101,\n",
    "                        sensitivity_threshold=0.75,\n",
    "                        save_dir=None,\n",
    "                        )\n",
    "    print(f\"**{clf_name}**\" * 30)\n",
    "    print(res)\n",
    "    print(f\"**{clf_name}**\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nyr0aAAsGXjZ"
   },
   "source": [
    "## Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frI5HH4q-1HS"
   },
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2n8a02zGfvP"
   },
   "source": [
    "## Scaling the Feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqcqn-nyAofk"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3VZvbwpGo9R"
   },
   "source": [
    "## Dividing data into training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1GW3VvQA7Rj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "upuczQ-KBHJ5",
    "outputId": "1431a28b-e8b6-4db2-e505-7e149e37c0d7"
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LtoE_FqqBzM8",
    "outputId": "76555a2b-2030-48e1-b52d-d71b4ebae38e"
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ir9XaWgQB0lq",
    "outputId": "2ec90814-19d8-4f27-934a-1ce54406d4ea"
   },
   "outputs": [],
   "source": [
    "X_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vp2yc5FWG04e"
   },
   "source": [
    "# Classification with Keras\n",
    "\n",
    "## Building our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qj3sc2uFEUMt"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='gelu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(32, activation='gelu'))\n",
    "model.add(layers.Dense(32, activation='gelu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yrsmpI6EjJ2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "bP0hVm4aElS7",
    "outputId": "aacf234d-d0a9-4de4-91be-5fd45a33b279"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=8,\n",
    "                    callbacks=callbacks.EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        min_delta=0.005,\n",
    "                        patience=5,\n",
    "                        verbose=0,\n",
    "                        mode='auto',\n",
    "                        baseline=None,\n",
    "                        restore_best_weights=True\n",
    "                    )\n",
    "                   )\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0m1J0_wUFK4C",
    "outputId": "ffd3bf36-29ea-437a-987c-9aa600b9dae6"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f6HrjXeUF0Ko",
    "outputId": "ea282dbd-6f9e-48c7-de2d-dc9afde8949e"
   },
   "outputs": [],
   "source": [
    "print('test_acc: ',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yQmP_f5Kq0w"
   },
   "source": [
    "Tes accuracy is less than training dataa accuracy. This hints at Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-U2qzRJoHV9O"
   },
   "source": [
    "## Validating our approach\n",
    "Let's set apart 200 samples in our training data to use as a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJNbvYZoF7ZT"
   },
   "outputs": [],
   "source": [
    "x_val = X_train[:200]\n",
    "partial_x_train = X_train[200:]\n",
    "\n",
    "y_val = y_train[:200]\n",
    "partial_y_train = y_train[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1EkG59EHeEV"
   },
   "source": [
    "Now let's train our network for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "Dp3G4P3aP4k2",
    "outputId": "25e1a389-1ac2-425b-bd5f-05736b6e9b96"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=30,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dljqHfDPI6lH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mvi9it1SI4aR",
    "outputId": "98b01ef2-3935-442b-82d6-45f56e036d39"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3hb8s1l4rBA"
   },
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gudBAhIXJIi2"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Xb7bVPSwJQF0",
    "outputId": "aca09c75-1d21-4847-bdd9-a0521dc8d948"
   },
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "llusRQV0JRy9",
    "outputId": "a856289d-883a-47cb-c0fb-ec148330a60a"
   },
   "outputs": [],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0eoEuSZqJTdU",
    "outputId": "94c17d00-dd7f-40a1-84d2-78d1ebde6103"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Utgt1bXfJVRN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Untitled9.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
